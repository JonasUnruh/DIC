{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66f28b29-a5ed-4fde-8842-7b7884de80ea",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Part 2 Datasets/DataFrames: Spark ML and Pipelines\n",
    "Convert the review texts to a classic vector space representation with TFIDF-weighted features based on the Spark DataFrame/Dataset API by building a transformation pipeline. The primary goal of this part is the preparation of the pipeline for Part 3 (see below). Note: although parts of this pipeline will be very similar to Assignment 1 or Part 1 above, do not expect to obtain identical results or have access to all intermediate outputs to compare the individual steps.\n",
    "\n",
    "Use built-in functions for tokenization to unigrams at whitespaces, tabs, digits, and the delimiter characters ()[]{}.!?,;:+=-_\"'`~#@&*%€$§\\/, casefolding, stopword removal, TF-IDF calculation, and chi square selection ) (using 2000 top terms overall). Write the terms selected this way to a file output_ds.txt and compare them with the terms selected in Assignment 1. Describe your observations briefly in the submission report (see Part 3).\n",
    "\n",
    "[Provided link for ML pipeline](https://spark.apache.org/docs/latest/ml-pipeline.html)  \n",
    "[Provided link for feature extraction](https://spark.apache.org/docs/latest/ml-features.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "506c5014-586e-4207-a1ee-4ae70578a208",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5c8870c8-86f0-4b27-bb23-897de467d592",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import StopWordsRemover\n",
    "from pyspark.ml.feature import IDF\n",
    "\n",
    "from pyspark.ml.feature import RegexTokenizer\n",
    "\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml.feature import CountVectorizer\n",
    "from pyspark.ml.feature import UnivariateFeatureSelector\n",
    "\n",
    "from pyspark.ml.classification import LinearSVC\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.tuning import ParamGridBuilder, TrainValidationSplit\n",
    "from pyspark.ml.classification import OneVsRest\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "from pyspark.ml.feature import Normalizer\n",
    "\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c4f196c8-c091-4a8c-9b1e-0cf1889e3578",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(action='once')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2338b89d-b829-47f2-b8a4-41237bf548e0",
   "metadata": {},
   "source": [
    "## Initialize Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "473068a3-f3cf-43f7-853b-caaede739ac6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/25 12:16:12 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "24/05/25 12:16:12 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n",
      "24/05/25 12:16:12 WARN Client: Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.\n"
     ]
    }
   ],
   "source": [
    "# Initialize Spark context and session\n",
    "conf = SparkConf().setAppName(\"Part2\")\n",
    "sc = SparkContext(conf=conf)\n",
    "spark = SparkSession(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a1b857ce-e484-4d92-991e-0b3c71d1ef7f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://jupyter01.os.hpc.tuwien.ac.at:4042\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.2.3</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>yarn</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Part2</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fd52f0f92b0>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abadc07e-77eb-48cb-8b6f-f444c7362aa1",
   "metadata": {},
   "source": [
    "### Importing data\n",
    "Stopwords file as well as test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0ee8fe45-dfdb-40c4-b0b6-727c45252da3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Define the stopwords file and the counters file\n",
    "stopwords_file = \"stopwords.txt\"\n",
    "\n",
    "# Load stopwords into a set\n",
    "with open(stopwords_file, \"r\") as f:\n",
    "    stopwords = set(f.read().strip().split())\n",
    "    \n",
    "# Load and preprocess the Amazon reviews dataset\n",
    "input_file = \"hdfs:///user/dic24_shared/amazon-reviews/full/reviews_devset.json\"\n",
    "reviews_df = spark.read.json(input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d527f40f-3aa7-4e2e-84c4-c0761ddb096e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|            category|          reviewText|\n",
      "+--------------------+--------------------+\n",
      "|Patio_Lawn_and_Garde|This was a gift f...|\n",
      "|Patio_Lawn_and_Garde|This is a very ni...|\n",
      "|Patio_Lawn_and_Garde|The metal base wi...|\n",
      "|Patio_Lawn_and_Garde|For the most part...|\n",
      "|Patio_Lawn_and_Garde|This hose is supp...|\n",
      "|Patio_Lawn_and_Garde|This tool works v...|\n",
      "|Patio_Lawn_and_Garde|This product is a...|\n",
      "|Patio_Lawn_and_Garde|I was excited to ...|\n",
      "|Patio_Lawn_and_Garde|I purchased the L...|\n",
      "|Patio_Lawn_and_Garde|Never used a manu...|\n",
      "|Patio_Lawn_and_Garde|Good price. Good ...|\n",
      "|Patio_Lawn_and_Garde|I have owned the ...|\n",
      "|Patio_Lawn_and_Garde|I had \"won\" a sim...|\n",
      "|Patio_Lawn_and_Garde|The birds ate all...|\n",
      "|Patio_Lawn_and_Garde|Bought last summe...|\n",
      "|Patio_Lawn_and_Garde|I knew I had a mo...|\n",
      "|Patio_Lawn_and_Garde|I was a little wo...|\n",
      "|Patio_Lawn_and_Garde|I have used this ...|\n",
      "|Patio_Lawn_and_Garde|I actually do not...|\n",
      "|Patio_Lawn_and_Garde|Just what I  expe...|\n",
      "+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "reviews_df = reviews_df.select(\"category\", \"reviewText\")\n",
    "\n",
    "# Show the DataFrame with selected columns\n",
    "reviews_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c9a960f-e270-441c-8ac3-459f7651f821",
   "metadata": {},
   "source": [
    "## Create RegexTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "018993a2-4daa-4020-a15a-1f755d9e97f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pattern = r'\\s+|\\d+|[(){}\\[\\].!?,;:+=_\"\\'`~#@&*%€$§\\\\/\\-]'\n",
    "regexTokenizer = RegexTokenizer(inputCol=\"reviewText\", outputCol=\"words\", pattern=pattern)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24675b04-1bd4-434d-81d7-4d021541c386",
   "metadata": {},
   "source": [
    "## Create StopWordsRemover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a935c1f3-84b4-478f-a6fb-b4718df9e7c7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "remover = StopWordsRemover(stopWords = list(stopwords), inputCol=\"words\", outputCol=\"filtered_words\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f995c64-2f56-43ce-8361-053506eff072",
   "metadata": {},
   "source": [
    "## Create CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a51d02b4-d9b5-444a-982a-a35605ea1440",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#hashingTF = HashingTF(inputCol=\"filtered_words\", outputCol=\"rawFeatures\")\n",
    "countV = CountVectorizer(inputCol=\"filtered_words\", outputCol=\"rawFeatures\").setMinTF(1).setMinDF(3).setVocabSize(7500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e86ae8be-1adb-4678-8734-9a58adbaea36",
   "metadata": {},
   "source": [
    "## Create IDF model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "939ee103-64d4-4175-8e00-32352ee5d453",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "idf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "760c3fcc-5a87-4ed9-9a94-76e373521982",
   "metadata": {},
   "source": [
    "## Create StringIndexer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "623e43a1-b476-459a-820a-328b88c5cea8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Apply StringIndexer to convert categorical column to numerical\n",
    "indexer = StringIndexer(inputCol=\"category\", outputCol=\"label\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c39ab712-7d3f-41d6-a524-a44c7fddf2ac",
   "metadata": {},
   "source": [
    "## Create Selector\n",
    "Here, we add a SelectionThreshold of 2000 to have the top 2000 terms overall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0bc18d5b-0676-400d-b052-7bef239683fa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UnivariateFeatureSelector_4f0c0881568c"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selector = UnivariateFeatureSelector(\n",
    "    featuresCol=\"features\",outputCol=\"selectedFeatures\",\n",
    "    labelCol=\"label\",  selectionMode=\"numTopFeatures\",\n",
    ")\n",
    "selector.setFeatureType(\"categorical\").setLabelType(\"categorical\").setSelectionThreshold(2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d384dbc-28c3-4d5f-9cad-8c1ef079c20f",
   "metadata": {},
   "source": [
    "## Create Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "da257682-1594-450c-b18f-29b3a328bf22",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pipeline = Pipeline(stages=[regexTokenizer, remover, countV, idf, indexer, selector])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d434b0f7-6550-44fc-8646-f03ef8d590a7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "model = pipeline.fit(reviews_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f2bcade8-b9d6-4f68-8da1-7f0df3981f3d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "result = model.transform(reviews_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b3ff37f8-dcd5-497e-8bd9-2cf7372c5e98",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|    selectedFeatures|\n",
      "+--------------------+\n",
      "|(2000,[2,3,7,8,35...|\n",
      "|(2000,[0,1,3,21,3...|\n",
      "|(2000,[4,10,174,3...|\n",
      "|(2000,[1,3,4,9,10...|\n",
      "|(2000,[12,29,101,...|\n",
      "|(2000,[0,3,4,8,11...|\n",
      "|(2000,[18,112,175...|\n",
      "|(2000,[6,21,32,36...|\n",
      "|(2000,[3,4,5,6,40...|\n",
      "|(2000,[6,8,38,78,...|\n",
      "|(2000,[1,13,226],...|\n",
      "|(2000,[5,17,33,40...|\n",
      "|(2000,[1,11,28,35...|\n",
      "|(2000,[40,144,339...|\n",
      "|(2000,[0,3,7,9,11...|\n",
      "|(2000,[8,26,57,80...|\n",
      "|(2000,[1,15,120,1...|\n",
      "|(2000,[2,3,221,26...|\n",
      "|(2000,[4,10,16,20...|\n",
      "|(2000,[0,18,30,42...|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result.select(\"selectedFeatures\").show(truncate=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43cf8864-ee28-4c1e-8385-7755946fabee",
   "metadata": {},
   "source": [
    "## Get top 2000 terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0fbaffe6-c201-4c37-bea8-cca0414943cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Extract vocabulary from CountVectorizer\n",
    "vocabulary = model.stages[2].vocabulary\n",
    "\n",
    "# Map selected feature indices to terms\n",
    "selected_terms = [vocabulary[i] for i in model.stages[-1].selectedFeatures]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "17a0630f-b8aa-4486-bc8f-02879a6439f4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(selected_terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "796e0a6e-2af6-4bfe-a982-517b0074d973",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary[:30] == selected_terms[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f65c8969-7816-4a5a-aed4-9c58fc81d2cd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(selected_terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8b1e266b-6ec9-44e3-afa8-e70e028c01f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(\"output_ds.txt\", \"w\") as f:\n",
    "    for term in selected_terms:\n",
    "        f.write(term + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c7210c9-6722-44af-a2bd-89e03b8e1558",
   "metadata": {},
   "source": [
    "# Part 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9deb93d7-f349-4b74-a96a-f10ec90d8844",
   "metadata": {},
   "source": [
    "In this part, you will train a text classifier from the features extracted in Part 2. The goal is to learn a model that can predict the product category from a review's text.\n",
    "\n",
    "To this end, extend the pipeline from Part 2 such that a Support Vector Machine classifier is trained. Since we are dealing with multi-class problems, make sure to put a strategy in place that allows binary classifiers to be applicable. Apply vector length normalization before feeding the feature vectors into the classifier (use Normalizer with L2 norm).\n",
    "\n",
    "Follow best practices for machine learning experiment design and investigate the effects of parameter settings using the functions provided by Spark:\n",
    "\n",
    "- Split the review data into training, validation, and test set.\n",
    "\n",
    "- Make experiments reproducible.\n",
    "\n",
    "- Use a grid search for parameter optimization:\n",
    "\n",
    "- Compare chi square overall top 2000 filtered features with another, heavier filtering with much less dimensionality (see Spark ML documentation for options).\n",
    "\n",
    "- Compare different SVM settings by varying the regularization parameter (choose 3 different values), standardization of training features (2 values), and maximum number of iterations (2 values).\n",
    "\n",
    "Use the MulticlassClassificationEvaluator to estimate performance of your trained classifiers on the test set, using F1 measure as criterion."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4caf75d-dc98-4bd9-a434-5c4bc2470812",
   "metadata": {},
   "source": [
    "## Split into Train/Test/Val and set seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c01a7465-d759-4da1-af46-19adfa162dea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "(reviews_train, reviews_test) = reviews_df.randomSplit([0.9, 0.1], 123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "54a58973-e718-4983-9b41-b88bdd677a91",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "71031"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_train.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "4b22113d-22e2-4c75-870d-df2f5838cf2f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7798"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_test.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "082d31d5-3c03-4887-b1a2-fbe4d688d637",
   "metadata": {},
   "source": [
    "## Extend Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "4888a1db-c5bc-42e8-ad6f-7e495d44f68f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "normalizer = Normalizer(inputCol=\"selectedFeatures\", outputCol=\"normalized_features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "732a8206-5357-491c-8fab-beb380ff7210",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "svm = LinearSVC(featuresCol=\"normalized_features\")\n",
    "ovr = OneVsRest(classifier=svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f43085d0-3833-45e8-be5b-7585da3c5649",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "extended_pipeline = Pipeline(stages=[regexTokenizer, remover, countV, idf, indexer, selector, normalizer, ovr])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b87a460-9ecb-4e85-ae1d-8b0a4fbe886a",
   "metadata": {},
   "source": [
    "## Define Evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ba203222-7590-42ce-a2d3-72bc825fe85f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "evaluator = MulticlassClassificationEvaluator(metricName=\"f1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fabb4d40-e73d-4910-9046-ac5e7d4fa092",
   "metadata": {},
   "source": [
    "## Perform Grid Search using different SVM settings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52d4e8a3-cadd-4b76-9af9-1b9e5db30968",
   "metadata": {},
   "source": [
    "Create a param grid to train and evaluate pipeline. Use TrainValidationSplit for single model per combination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "bbcdb0b5-fa05-4633-8846-c9a3fe6503d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "param_grid = ParamGridBuilder() \\\n",
    "    .addGrid(svm.regParam, [0.1, 0.01, 0.001]) \\\n",
    "    .addGrid(svm.maxIter, [10, 20]) \\\n",
    "    .addGrid(svm.standardization, [True, False]) \\\n",
    "    .addGrid(selector.selectionThreshold, [2000, 250]) \\\n",
    "    .build()\n",
    "\n",
    "validator = TrainValidationSplit(estimator=extended_pipeline, estimatorParamMaps=param_grid, evaluator=evaluator, trainRatio = 0.7, parallelism = 4, seed=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d1b34a-0801-4a13-9310-fc8ee9bcddda",
   "metadata": {},
   "source": [
    "Perform a grid search on a subset of the training data to approximate the best parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "2060737a-f82c-4b67-9f39-3caebeaf086a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.9/socket.py:775: ResourceWarning: unclosed <socket.socket fd=72, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('127.0.0.1', 42824), raddr=('127.0.0.1', 37831)>\n",
      "  self._sock = None\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "/usr/lib64/python3.9/socket.py:775: ResourceWarning: unclosed <socket.socket fd=75, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('127.0.0.1', 55550), raddr=('127.0.0.1', 44155)>\n",
      "  self._sock = None\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "/usr/lib64/python3.9/socket.py:775: ResourceWarning: unclosed <socket.socket fd=78, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('127.0.0.1', 35038), raddr=('127.0.0.1', 41467)>\n",
      "  self._sock = None\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "/usr/lib64/python3.9/socket.py:775: ResourceWarning: unclosed <socket.socket fd=81, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('127.0.0.1', 35034), raddr=('127.0.0.1', 42751)>\n",
      "  self._sock = None\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "/usr/lib64/python3.9/multiprocessing/pool.py:265: ResourceWarning: unclosed running multiprocessing pool <multiprocessing.pool.ThreadPool state=RUN pool_size=1>\n",
      "  _warn(f\"unclosed running multiprocessing pool {self!r}\",\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "24/05/25 12:29:27 WARN DAGScheduler: Broadcasting large task binary with size 1822.2 KiB\n",
      "24/05/25 12:29:27 WARN DAGScheduler: Broadcasting large task binary with size 1822.2 KiB\n",
      "24/05/25 12:29:27 WARN DAGScheduler: Broadcasting large task binary with size 1822.2 KiB\n",
      "24/05/25 12:29:27 WARN DAGScheduler: Broadcasting large task binary with size 1822.2 KiB\n",
      "/usr/lib64/python3.9/socket.py:775: ResourceWarning: unclosed <socket.socket fd=73, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('127.0.0.1', 51290), raddr=('127.0.0.1', 34247)>\n",
      "  self._sock = None\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "/usr/lib64/python3.9/socket.py:775: ResourceWarning: unclosed <socket.socket fd=76, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('127.0.0.1', 51882), raddr=('127.0.0.1', 35411)>\n",
      "  self._sock = None\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "/usr/lib64/python3.9/socket.py:775: ResourceWarning: unclosed <socket.socket fd=76, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('127.0.0.1', 33730), raddr=('127.0.0.1', 34089)>\n",
      "  self._sock = None\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "/usr/lib64/python3.9/socket.py:775: ResourceWarning: unclosed <socket.socket fd=82, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('127.0.0.1', 33354), raddr=('127.0.0.1', 33475)>\n",
      "  self._sock = None\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "24/05/25 12:42:43 WARN DAGScheduler: Broadcasting large task binary with size 1822.2 KiB\n",
      "24/05/25 12:42:44 WARN DAGScheduler: Broadcasting large task binary with size 1822.2 KiB\n",
      "24/05/25 12:42:44 WARN DAGScheduler: Broadcasting large task binary with size 1822.2 KiB\n",
      "24/05/25 12:42:44 WARN DAGScheduler: Broadcasting large task binary with size 1822.2 KiB\n",
      "/usr/lib64/python3.9/socket.py:775: ResourceWarning: unclosed <socket.socket fd=73, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('127.0.0.1', 57956), raddr=('127.0.0.1', 42649)>\n",
      "  self._sock = None\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "/usr/lib64/python3.9/socket.py:775: ResourceWarning: unclosed <socket.socket fd=76, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('127.0.0.1', 34908), raddr=('127.0.0.1', 38741)>\n",
      "  self._sock = None\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "/usr/lib64/python3.9/socket.py:775: ResourceWarning: unclosed <socket.socket fd=79, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('127.0.0.1', 45118), raddr=('127.0.0.1', 45421)>\n",
      "  self._sock = None\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "/usr/lib64/python3.9/socket.py:775: ResourceWarning: unclosed <socket.socket fd=82, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('127.0.0.1', 51764), raddr=('127.0.0.1', 34469)>\n",
      "  self._sock = None\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "24/05/25 12:55:24 WARN DAGScheduler: Broadcasting large task binary with size 1822.2 KiB\n",
      "24/05/25 12:55:24 WARN DAGScheduler: Broadcasting large task binary with size 1822.2 KiB\n",
      "24/05/25 12:55:24 WARN DAGScheduler: Broadcasting large task binary with size 1822.2 KiB\n",
      "24/05/25 12:55:24 WARN DAGScheduler: Broadcasting large task binary with size 1822.2 KiB\n",
      "/usr/lib64/python3.9/socket.py:775: ResourceWarning: unclosed <socket.socket fd=73, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('127.0.0.1', 47504), raddr=('127.0.0.1', 41979)>\n",
      "  self._sock = None\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "/usr/lib64/python3.9/socket.py:775: ResourceWarning: unclosed <socket.socket fd=76, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('127.0.0.1', 47720), raddr=('127.0.0.1', 43873)>\n",
      "  self._sock = None\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "/usr/lib64/python3.9/socket.py:775: ResourceWarning: unclosed <socket.socket fd=76, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('127.0.0.1', 51992), raddr=('127.0.0.1', 44467)>\n",
      "  self._sock = None\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "/usr/lib64/python3.9/socket.py:775: ResourceWarning: unclosed <socket.socket fd=82, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('127.0.0.1', 53570), raddr=('127.0.0.1', 42721)>\n",
      "  self._sock = None\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "24/05/25 13:08:34 WARN DAGScheduler: Broadcasting large task binary with size 1822.2 KiB\n",
      "24/05/25 13:08:34 WARN DAGScheduler: Broadcasting large task binary with size 1822.2 KiB\n",
      "24/05/25 13:08:34 WARN DAGScheduler: Broadcasting large task binary with size 1822.2 KiB\n",
      "24/05/25 13:08:34 WARN DAGScheduler: Broadcasting large task binary with size 1822.2 KiB\n",
      "/usr/lib64/python3.9/socket.py:775: ResourceWarning: unclosed <socket.socket fd=73, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('127.0.0.1', 43060), raddr=('127.0.0.1', 37781)>\n",
      "  self._sock = None\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "/usr/lib64/python3.9/socket.py:775: ResourceWarning: unclosed <socket.socket fd=76, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('127.0.0.1', 46196), raddr=('127.0.0.1', 43773)>\n",
      "  self._sock = None\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "/usr/lib64/python3.9/socket.py:775: ResourceWarning: unclosed <socket.socket fd=76, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('127.0.0.1', 37640), raddr=('127.0.0.1', 44823)>\n",
      "  self._sock = None\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "/usr/lib64/python3.9/socket.py:775: ResourceWarning: unclosed <socket.socket fd=82, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('127.0.0.1', 40440), raddr=('127.0.0.1', 42953)>\n",
      "  self._sock = None\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "24/05/25 13:21:06 WARN DAGScheduler: Broadcasting large task binary with size 1822.2 KiB\n",
      "24/05/25 13:21:06 WARN DAGScheduler: Broadcasting large task binary with size 1822.2 KiB\n",
      "24/05/25 13:21:06 WARN DAGScheduler: Broadcasting large task binary with size 1822.2 KiB\n",
      "24/05/25 13:21:06 WARN DAGScheduler: Broadcasting large task binary with size 1822.2 KiB\n",
      "/usr/lib64/python3.9/socket.py:775: ResourceWarning: unclosed <socket.socket fd=73, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('127.0.0.1', 35870), raddr=('127.0.0.1', 38225)>\n",
      "  self._sock = None\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "/usr/lib64/python3.9/socket.py:775: ResourceWarning: unclosed <socket.socket fd=76, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('127.0.0.1', 44800), raddr=('127.0.0.1', 40725)>\n",
      "  self._sock = None\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "/usr/lib64/python3.9/socket.py:775: ResourceWarning: unclosed <socket.socket fd=79, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('127.0.0.1', 57708), raddr=('127.0.0.1', 37751)>\n",
      "  self._sock = None\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "/usr/lib64/python3.9/socket.py:775: ResourceWarning: unclosed <socket.socket fd=79, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('127.0.0.1', 43572), raddr=('127.0.0.1', 33473)>\n",
      "  self._sock = None\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "24/05/25 13:34:14 WARN DAGScheduler: Broadcasting large task binary with size 1822.2 KiB\n",
      "24/05/25 13:34:14 WARN DAGScheduler: Broadcasting large task binary with size 1822.2 KiB\n",
      "24/05/25 13:34:15 WARN DAGScheduler: Broadcasting large task binary with size 1822.2 KiB\n",
      "24/05/25 13:34:15 WARN DAGScheduler: Broadcasting large task binary with size 1822.2 KiB\n",
      "/usr/lib64/python3.9/socket.py:775: ResourceWarning: unclosed <socket.socket fd=73, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('127.0.0.1', 47694), raddr=('127.0.0.1', 45481)>\n",
      "  self._sock = None\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "/usr/lib64/python3.9/multiprocessing/pool.py:265: ResourceWarning: unclosed running multiprocessing pool <multiprocessing.pool.ThreadPool state=RUN pool_size=4>\n",
      "  _warn(f\"unclosed running multiprocessing pool {self!r}\",\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    }
   ],
   "source": [
    "start_time = datetime.now()\n",
    "cv_model = validator.fit(reviews_train)\n",
    "end_time = datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "047e3af8-3bc3-432c-9264-6e56d6398d5f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start time: 2024-05-25 12:17:08.399678\n",
      "end time: 2024-05-25 13:39:32.794385\n",
      "time elapsed: 1:22:24.394707\n",
      "\n",
      "no. reviews used to train: 71031\n",
      "no. reviews used to test: 7798\n"
     ]
    }
   ],
   "source": [
    "print(\"start time:\", start_time)\n",
    "print(\"end time:\", end_time)\n",
    "print(\"time elapsed:\", end_time - start_time)\n",
    "\n",
    "print(\"\\nno. reviews used to train:\", reviews_train.count())\n",
    "print(\"no. reviews used to test:\", reviews_test.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "94dba137-acbe-4c7c-845d-8b362d4a8a76",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params:\n",
      "RegParam: 0.01\n",
      "MaxIter: 10\n",
      "Standardization: False\n",
      "P value: 2000.0\n"
     ]
    }
   ],
   "source": [
    "# Get the best model\n",
    "bestModel = cv_model.bestModel\n",
    "\n",
    "# Show the best parameters\n",
    "print(\"Best Params:\")\n",
    "print(\"RegParam:\", bestModel.stages[-1].models[0].getOrDefault(\"regParam\"))\n",
    "print(\"MaxIter:\", bestModel.stages[-1].models[0].getOrDefault(\"maxIter\"))\n",
    "print(\"Standardization:\", bestModel.stages[-1].models[0].getOrDefault(\"standardization\"))\n",
    "print(\"P value:\", bestModel.stages[-3].getOrDefault(\"selectionThreshold\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "d8fb2c7a-f784-44b3-ba32-938a5ffdc463",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/25 13:39:38 WARN DAGScheduler: Broadcasting large task binary with size 1819.0 KiB\n",
      "[Stage 19636:===========================>                           (1 + 1) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.630127489411732\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "predictions = cv_model.transform(reviews_test)\n",
    "\n",
    "f1_score = evaluator.evaluate(predictions)\n",
    "print(f\"F1 Score: {f1_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "fde8336d-935f-4434-b584-5100cb041d2f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (DIC24)",
   "language": "python",
   "name": "python3_dic24"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
